{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base vs Steering 詳細分析\n",
    "\n",
    "**目的**: Baseに90.2%引き分け、84.6%のpersonasで全く差が出なかったSteeringを分析\n",
    "\n",
    "**分析内容**:\n",
    "1. 最適化された重みの分布と特徴\n",
    "2. 差が出たpersona vs 出なかったpersonaの重みパターン比較\n",
    "3. 重みの大きさとSteering効果の関係\n",
    "4. Trait別の重み分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msns\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpathlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcollections\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m defaultdict\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "\n",
    "# 日本語フォント設定\n",
    "plt.rcParams['font.sans-serif'] = ['DejaVu Sans']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# スタイル設定\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"✓ Libraries loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. データロード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load validation results\n",
    "with open(\"../results/base_vs_steering/summary.json\") as f:\n",
    "    summary = json.load(f)\n",
    "\n",
    "with open(\"../results/base_vs_steering/comparison_results.json\") as f:\n",
    "    comparison_data = json.load(f)\n",
    "\n",
    "results = comparison_data[\"results\"]\n",
    "\n",
    "print(f\"Total comparisons: {summary['total_comparisons']}\")\n",
    "print(f\"Tie rate: {summary['win_rates']['tie']*100:.1f}%\")\n",
    "print(f\"Steering win rate (decisive only): {summary['decisive_win_rates']['steering']*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load optimized weights for all personas\n",
    "weights_dir = Path(\"../optimization_results_26personas\")\n",
    "\n",
    "all_weights = {}\n",
    "for gpu_dir in [\"gpu0\", \"gpu1\"]:\n",
    "    gpu_path = weights_dir / gpu_dir\n",
    "    if gpu_path.exists():\n",
    "        for weight_file in gpu_path.glob(\"*_best_weights.json\"):\n",
    "            persona_id = weight_file.stem.replace(\"_best_weights\", \"\")\n",
    "            with open(weight_file) as f:\n",
    "                all_weights[persona_id] = json.load(f)\n",
    "\n",
    "print(f\"Loaded weights for {len(all_weights)} personas\")\n",
    "print(f\"Personas: {sorted(all_weights.keys())[:5]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Persona分類: 差が出た vs 出なかった"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorize personas by outcome\n",
    "persona_outcomes = defaultdict(lambda: {\"tie\": 0, \"steering\": 0, \"base\": 0})\n",
    "\n",
    "for r in results:\n",
    "    persona_id = r[\"persona_id\"]\n",
    "    winner = r[\"winner\"]\n",
    "    persona_outcomes[persona_id][winner] += 1\n",
    "\n",
    "# Classify personas\n",
    "all_tie_personas = []\n",
    "mixed_personas = []\n",
    "\n",
    "for persona_id, outcomes in persona_outcomes.items():\n",
    "    total = sum(outcomes.values())\n",
    "    if outcomes[\"tie\"] == total:\n",
    "        all_tie_personas.append(persona_id)\n",
    "    else:\n",
    "        mixed_personas.append(persona_id)\n",
    "\n",
    "print(f\"All-tie personas (no effect): {len(all_tie_personas)} ({100*len(all_tie_personas)/len(persona_outcomes):.1f}%)\")\n",
    "print(f\"Mixed personas (some effect): {len(mixed_personas)} ({100*len(mixed_personas)/len(persona_outcomes):.1f}%)\")\n",
    "\n",
    "# Show mixed personas with details\n",
    "print(\"\\nMixed personas (steering had some effect):\")\n",
    "for persona_id in sorted(mixed_personas):\n",
    "    outcomes = persona_outcomes[persona_id]\n",
    "    total = sum(outcomes.values())\n",
    "    print(f\"  {persona_id}:\")\n",
    "    print(f\"    Tie: {outcomes['tie']}/{total} ({100*outcomes['tie']/total:.1f}%)\")\n",
    "    print(f\"    Steering: {outcomes['steering']}/{total} ({100*outcomes['steering']/total:.1f}%)\")\n",
    "    print(f\"    Base: {outcomes['base']}/{total} ({100*outcomes['base']/total:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 重みの分布分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert weights to DataFrame\n",
    "weights_data = []\n",
    "for persona_id, weights in all_weights.items():\n",
    "    # Determine if persona had effect\n",
    "    had_effect = persona_id in mixed_personas\n",
    "    \n",
    "    row = {\n",
    "        \"persona_id\": persona_id,\n",
    "        \"had_effect\": had_effect,\n",
    "        \"R1\": weights.get(\"R1\", 0.0),\n",
    "        \"R2\": weights.get(\"R2\", 0.0),\n",
    "        \"R3\": weights.get(\"R3\", 0.0),\n",
    "        \"R4\": weights.get(\"R4\", 0.0),\n",
    "        \"R5\": weights.get(\"R5\", 0.0)\n",
    "    }\n",
    "    \n",
    "    # Compute statistics\n",
    "    weight_values = [row[f\"R{i}\"] for i in range(1, 6)]\n",
    "    row[\"weight_mean\"] = np.mean(weight_values)\n",
    "    row[\"weight_std\"] = np.std(weight_values)\n",
    "    row[\"weight_abs_mean\"] = np.mean(np.abs(weight_values))\n",
    "    row[\"weight_l2_norm\"] = np.linalg.norm(weight_values)\n",
    "    \n",
    "    weights_data.append(row)\n",
    "\n",
    "df_weights = pd.DataFrame(weights_data)\n",
    "df_weights.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics by effect group\n",
    "print(\"Weight statistics by effect group:\\n\")\n",
    "print(df_weights.groupby(\"had_effect\")[[\"weight_mean\", \"weight_std\", \"weight_abs_mean\", \"weight_l2_norm\"]].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 可視化: 重みの分布"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 1: Weight distributions by trait\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "traits = [\"R1\", \"R2\", \"R3\", \"R4\", \"R5\"]\n",
    "\n",
    "for i, trait in enumerate(traits):\n",
    "    ax = axes[i]\n",
    "    \n",
    "    # Plot distributions\n",
    "    no_effect = df_weights[~df_weights[\"had_effect\"]][trait]\n",
    "    had_effect = df_weights[df_weights[\"had_effect\"]][trait]\n",
    "    \n",
    "    ax.hist(no_effect, alpha=0.5, label=f\"No effect (n={len(no_effect)})\", bins=15, color=\"blue\")\n",
    "    ax.hist(had_effect, alpha=0.5, label=f\"Had effect (n={len(had_effect)})\", bins=15, color=\"red\")\n",
    "    \n",
    "    ax.axvline(0, color='black', linestyle='--', linewidth=1, alpha=0.5)\n",
    "    ax.set_xlabel(f\"{trait} Weight\")\n",
    "    ax.set_ylabel(\"Count\")\n",
    "    ax.set_title(f\"{trait} Weight Distribution\")\n",
    "    ax.legend()\n",
    "    ax.grid(alpha=0.3)\n",
    "\n",
    "# Remove empty subplot\n",
    "fig.delaxes(axes[5])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../results/base_vs_steering/weight_distributions.png\", dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Saved: results/base_vs_steering/weight_distributions.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 2: L2 norm comparison\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "no_effect_norm = df_weights[~df_weights[\"had_effect\"]][\"weight_l2_norm\"]\n",
    "had_effect_norm = df_weights[df_weights[\"had_effect\"]][\"weight_l2_norm\"]\n",
    "\n",
    "positions = [1, 2]\n",
    "bp = ax.boxplot([no_effect_norm, had_effect_norm], \n",
    "                 labels=[\"No Effect\\n(n=22)\", \"Had Effect\\n(n=4)\"],\n",
    "                 patch_artist=True,\n",
    "                 showmeans=True)\n",
    "\n",
    "bp['boxes'][0].set_facecolor('lightblue')\n",
    "bp['boxes'][1].set_facecolor('lightcoral')\n",
    "\n",
    "ax.set_ylabel(\"L2 Norm of Weights\")\n",
    "ax.set_title(\"Weight Vector Magnitude: Effect vs No Effect\")\n",
    "ax.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../results/base_vs_steering/weight_l2_norm_comparison.png\", dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Saved: results/base_vs_steering/weight_l2_norm_comparison.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 重みパターンの可視化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap of weights\n",
    "weight_matrix = df_weights[[\"R1\", \"R2\", \"R3\", \"R4\", \"R5\"]].values\n",
    "persona_labels = df_weights[\"persona_id\"].values\n",
    "effect_labels = [\"*\" if had else \"\" for had in df_weights[\"had_effect\"]]\n",
    "row_labels = [f\"{persona}{effect}\" for persona, effect in zip(persona_labels, effect_labels)]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 14))\n",
    "sns.heatmap(weight_matrix, \n",
    "            xticklabels=[\"R1\", \"R2\", \"R3\", \"R4\", \"R5\"],\n",
    "            yticklabels=row_labels,\n",
    "            cmap=\"RdBu_r\",\n",
    "            center=0,\n",
    "            annot=True,\n",
    "            fmt=\".2f\",\n",
    "            cbar_kws={'label': 'Weight Value'},\n",
    "            ax=ax)\n",
    "\n",
    "ax.set_title(\"Optimized Weights Heatmap\\n(* = Had effect on generation)\")\n",
    "ax.set_xlabel(\"Trait\")\n",
    "ax.set_ylabel(\"Persona\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../results/base_vs_steering/weights_heatmap.png\", dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Saved: results/base_vs_steering/weights_heatmap.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 相関分析: 重みの大きさ vs Steering効果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add outcome metrics to dataframe\n",
    "for idx, row in df_weights.iterrows():\n",
    "    persona_id = row[\"persona_id\"]\n",
    "    outcomes = persona_outcomes[persona_id]\n",
    "    total = sum(outcomes.values())\n",
    "    \n",
    "    df_weights.loc[idx, \"steering_win_rate\"] = outcomes[\"steering\"] / total if total > 0 else 0\n",
    "    df_weights.loc[idx, \"decisive_rate\"] = (outcomes[\"steering\"] + outcomes[\"base\"]) / total if total > 0 else 0\n",
    "\n",
    "# Correlation analysis\n",
    "print(\"Correlation between weight magnitude and steering effect:\\n\")\n",
    "print(df_weights[[\"weight_l2_norm\", \"weight_abs_mean\", \"weight_std\", \"steering_win_rate\", \"decisive_rate\"]].corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot: L2 norm vs decisive rate\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Plot 1: L2 norm vs decisive rate\n",
    "ax = axes[0]\n",
    "colors = ['red' if had else 'blue' for had in df_weights[\"had_effect\"]]\n",
    "ax.scatter(df_weights[\"weight_l2_norm\"], df_weights[\"decisive_rate\"], c=colors, alpha=0.6, s=100)\n",
    "ax.set_xlabel(\"L2 Norm of Weights\")\n",
    "ax.set_ylabel(\"Decisive Rate (non-tie proportion)\")\n",
    "ax.set_title(\"Weight Magnitude vs Steering Effect\")\n",
    "ax.grid(alpha=0.3)\n",
    "\n",
    "# Add legend\n",
    "from matplotlib.patches import Patch\n",
    "legend_elements = [Patch(facecolor='red', label='Had effect'),\n",
    "                   Patch(facecolor='blue', label='No effect')]\n",
    "ax.legend(handles=legend_elements)\n",
    "\n",
    "# Plot 2: Abs mean vs steering win rate (among decisive)\n",
    "ax = axes[1]\n",
    "# Only plot personas with some decisive comparisons\n",
    "decisive_df = df_weights[df_weights[\"decisive_rate\"] > 0]\n",
    "colors = ['red' if had else 'blue' for had in decisive_df[\"had_effect\"]]\n",
    "ax.scatter(decisive_df[\"weight_abs_mean\"], decisive_df[\"steering_win_rate\"], c=colors, alpha=0.6, s=100)\n",
    "ax.set_xlabel(\"Mean Absolute Weight\")\n",
    "ax.set_ylabel(\"Steering Win Rate (among all comparisons)\")\n",
    "ax.set_title(\"Weight Magnitude vs Steering Win Rate\")\n",
    "ax.grid(alpha=0.3)\n",
    "ax.legend(handles=legend_elements)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../results/base_vs_steering/weight_effect_correlation.png\", dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Saved: results/base_vs_steering/weight_effect_correlation.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 効果があったPersonasの詳細分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed analysis of effective personas\n",
    "print(\"=\"*80)\n",
    "print(\"DETAILED ANALYSIS: Personas where steering had effect\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for persona_id in sorted(mixed_personas):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Persona: {persona_id}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Weights\n",
    "    weights = all_weights[persona_id]\n",
    "    print(\"\\nOptimized Weights:\")\n",
    "    for trait, weight in sorted(weights.items()):\n",
    "        print(f\"  {trait}: {weight:+.3f}\")\n",
    "    \n",
    "    weight_values = [weights[f\"R{i}\"] for i in range(1, 6)]\n",
    "    print(f\"\\nWeight Statistics:\")\n",
    "    print(f\"  L2 norm: {np.linalg.norm(weight_values):.3f}\")\n",
    "    print(f\"  Mean abs: {np.mean(np.abs(weight_values)):.3f}\")\n",
    "    print(f\"  Std: {np.std(weight_values):.3f}\")\n",
    "    \n",
    "    # Outcomes\n",
    "    outcomes = persona_outcomes[persona_id]\n",
    "    total = sum(outcomes.values())\n",
    "    print(f\"\\nOutcomes (n={total}):\")\n",
    "    print(f\"  Tie: {outcomes['tie']} ({100*outcomes['tie']/total:.1f}%)\")\n",
    "    print(f\"  Steering wins: {outcomes['steering']} ({100*outcomes['steering']/total:.1f}%)\")\n",
    "    print(f\"  Base wins: {outcomes['base']} ({100*outcomes['base']/total:.1f}%)\")\n",
    "    print(f\"  Decisive rate: {100*(outcomes['steering']+outcomes['base'])/total:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Trait別の効果分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare trait weights between effect groups\n",
    "trait_comparison = df_weights.groupby(\"had_effect\")[[\"R1\", \"R2\", \"R3\", \"R4\", \"R5\"]].agg(['mean', 'std', 'median'])\n",
    "\n",
    "print(\"Trait weight comparison: Effect vs No Effect\")\n",
    "print(trait_comparison)\n",
    "\n",
    "# Statistical test (t-test)\n",
    "from scipy import stats\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"T-test: Effect vs No Effect (for each trait)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for trait in [\"R1\", \"R2\", \"R3\", \"R4\", \"R5\"]:\n",
    "    no_effect_vals = df_weights[~df_weights[\"had_effect\"]][trait]\n",
    "    had_effect_vals = df_weights[df_weights[\"had_effect\"]][trait]\n",
    "    \n",
    "    t_stat, p_value = stats.ttest_ind(no_effect_vals, had_effect_vals)\n",
    "    \n",
    "    print(f\"\\n{trait}:\")\n",
    "    print(f\"  No effect: mean={no_effect_vals.mean():.3f}, std={no_effect_vals.std():.3f}\")\n",
    "    print(f\"  Had effect: mean={had_effect_vals.mean():.3f}, std={had_effect_vals.std():.3f}\")\n",
    "    print(f\"  t-statistic: {t_stat:.3f}\")\n",
    "    print(f\"  p-value: {p_value:.4f}\")\n",
    "    print(f\"  Significant (p<0.05): {p_value < 0.05}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. まとめと考察"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"SUMMARY: Why Steering Failed for 84.6% of Personas\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n1. Overall Statistics:\")\n",
    "print(f\"   - Total personas: {len(df_weights)}\")\n",
    "print(f\"   - No effect: {len(all_tie_personas)} ({100*len(all_tie_personas)/len(df_weights):.1f}%)\")\n",
    "print(f\"   - Had effect: {len(mixed_personas)} ({100*len(mixed_personas)/len(df_weights):.1f}%)\")\n",
    "\n",
    "print(\"\\n2. Weight Magnitude Comparison:\")\n",
    "no_effect_norm_mean = df_weights[~df_weights[\"had_effect\"]][\"weight_l2_norm\"].mean()\n",
    "had_effect_norm_mean = df_weights[df_weights[\"had_effect\"]][\"weight_l2_norm\"].mean()\n",
    "print(f\"   - No effect group L2 norm: {no_effect_norm_mean:.3f}\")\n",
    "print(f\"   - Had effect group L2 norm: {had_effect_norm_mean:.3f}\")\n",
    "print(f\"   - Difference: {had_effect_norm_mean - no_effect_norm_mean:.3f}\")\n",
    "\n",
    "print(\"\\n3. Possible Explanations:\")\n",
    "print(\"   a) Optimization converged to near-zero weights for most personas\")\n",
    "print(\"   b) Trait vectors don't capture persona-specific characteristics\")\n",
    "print(\"   c) Layer 20 may not be the optimal intervention point\")\n",
    "print(\"   d) Alpha=2.0 scaling may be insufficient to produce observable effects\")\n",
    "print(\"   e) Judge (GPT-4o) may not detect subtle stylistic differences\")\n",
    "\n",
    "print(\"\\n4. Recommendations:\")\n",
    "print(\"   - Investigate why optimization produces small weights\")\n",
    "print(\"   - Try different layers and larger alpha values\")\n",
    "print(\"   - Use more sensitive evaluation metrics\")\n",
    "print(\"   - Consider persona-specific trait vector construction\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. エクスポート: 分析結果を保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save analysis results\n",
    "analysis_results = {\n",
    "    \"summary\": {\n",
    "        \"total_personas\": len(df_weights),\n",
    "        \"no_effect_personas\": len(all_tie_personas),\n",
    "        \"had_effect_personas\": len(mixed_personas),\n",
    "        \"no_effect_rate\": len(all_tie_personas) / len(df_weights)\n",
    "    },\n",
    "    \"weight_statistics\": {\n",
    "        \"no_effect_group\": {\n",
    "            \"l2_norm_mean\": float(df_weights[~df_weights[\"had_effect\"]][\"weight_l2_norm\"].mean()),\n",
    "            \"l2_norm_std\": float(df_weights[~df_weights[\"had_effect\"]][\"weight_l2_norm\"].std()),\n",
    "            \"abs_mean_mean\": float(df_weights[~df_weights[\"had_effect\"]][\"weight_abs_mean\"].mean()),\n",
    "        },\n",
    "        \"had_effect_group\": {\n",
    "            \"l2_norm_mean\": float(df_weights[df_weights[\"had_effect\"]][\"weight_l2_norm\"].mean()),\n",
    "            \"l2_norm_std\": float(df_weights[df_weights[\"had_effect\"]][\"weight_l2_norm\"].std()),\n",
    "            \"abs_mean_mean\": float(df_weights[df_weights[\"had_effect\"]][\"weight_abs_mean\"].mean()),\n",
    "        }\n",
    "    },\n",
    "    \"effective_personas\": [\n",
    "        {\n",
    "            \"persona_id\": persona_id,\n",
    "            \"weights\": all_weights[persona_id],\n",
    "            \"outcomes\": dict(persona_outcomes[persona_id]),\n",
    "            \"steering_win_rate\": float(df_weights[df_weights[\"persona_id\"]==persona_id][\"steering_win_rate\"].iloc[0]),\n",
    "            \"decisive_rate\": float(df_weights[df_weights[\"persona_id\"]==persona_id][\"decisive_rate\"].iloc[0])\n",
    "        }\n",
    "        for persona_id in sorted(mixed_personas)\n",
    "    ]\n",
    "}\n",
    "\n",
    "with open(\"../results/base_vs_steering/weight_analysis.json\", \"w\") as f:\n",
    "    json.dump(analysis_results, f, indent=2)\n",
    "\n",
    "print(\"✓ Saved: results/base_vs_steering/weight_analysis.json\")\n",
    "\n",
    "# Save weights dataframe\n",
    "df_weights.to_csv(\"../results/base_vs_steering/weights_dataframe.csv\", index=False)\n",
    "print(\"✓ Saved: results/base_vs_steering/weights_dataframe.csv\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Analysis complete! All results saved.\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "persona2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
