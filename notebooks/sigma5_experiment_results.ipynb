{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ïƒ=5.0æœ€é©åŒ–å®Ÿé¨“ - å®Œå…¨ãƒ¬ãƒãƒ¼ãƒˆ\n",
    "\n",
    "**å®Ÿæ–½æœŸé–“**: 2026-01-08 ~ 2026-01-10  \n",
    "**ç›®çš„**: CMA-ESã®Ïƒãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿èª¿æ•´ã«ã‚ˆã‚‹L2ãƒãƒ«ãƒ å¢—åŠ ã¨SteeringåŠ¹æœã®æ”¹å–„  \n",
    "**å¯¾è±¡**: 28ãƒšãƒ«ã‚½ãƒŠ + Î±Ã—Ïƒèª¿æ•´å®Ÿé¨“"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "# Matplotlibæ—¥æœ¬èªå¯¾å¿œ\n",
    "plt.rcParams['font.sans-serif'] = ['DejaVu Sans']\n",
    "plt.rcParams['axes.unicode_minus'] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. å®Ÿé¨“æ¦‚è¦\n",
    "\n",
    "### èƒŒæ™¯\n",
    "\n",
    "26ãƒšãƒ«ã‚½ãƒŠæœ€é©åŒ–ã§å¾—ã‚‰ã‚ŒãŸèª²é¡Œ:\n",
    "- **L2ãƒãƒ«ãƒ  < 4** ã®ãƒšãƒ«ã‚½ãƒŠãŒ22/26 (85%)\n",
    "- SteeringåŠ¹æœãŒä¸ååˆ†\n",
    "\n",
    "### ä»®èª¬\n",
    "\n",
    "1. **Î±ï¼ˆSteeringå¼·åº¦ï¼‰**ã‚’å¢—ã‚„ã›ã°L2ãŒå¢—ãˆã‚‹ï¼Ÿ\n",
    "2. **Ïƒï¼ˆCMA-ESæ¢ç´¢å¹…ï¼‰**ã‚’å¢—ã‚„ã›ã°L2ãŒå¢—ãˆã‚‹ï¼Ÿ\n",
    "\n",
    "### å®Ÿé¨“ãƒ‡ã‚¶ã‚¤ãƒ³\n",
    "\n",
    "#### Part 1: Î±Ã—Ïƒèª¿æ•´å®Ÿé¨“ï¼ˆ1ãƒšãƒ«ã‚½ãƒŠ: episode-184019_Aï¼‰\n",
    "\n",
    "| æ¡ä»¶ | Î± | Ïƒ | ç›®çš„ |\n",
    "|------|---|---|------|\n",
    "| baseline | 2.0 | 2.0 | ç¾çŠ¶æŠŠæ¡ |\n",
    "| high_alpha | 5.0 | 2.0 | Î±åŠ¹æœã®æ¤œè¨¼ |\n",
    "| high_sigma | 2.0 | 5.0 | ÏƒåŠ¹æœã®æ¤œè¨¼ |\n",
    "| high_both | 5.0 | 5.0 | çµ„ã¿åˆã‚ã›åŠ¹æœ |\n",
    "\n",
    "#### Part 2: Ïƒ=5.0å…¨ãƒšãƒ«ã‚½ãƒŠæœ€é©åŒ–ï¼ˆ28ãƒšãƒ«ã‚½ãƒŠï¼‰\n",
    "\n",
    "- Part 1ã®çµæœã‚’è¸ã¾ãˆã€Ïƒ=5.0ã§28ãƒšãƒ«ã‚½ãƒŠã‚’æœ€é©åŒ–"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Part 1: Î±Ã—Ïƒèª¿æ•´å®Ÿé¨“çµæœ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Î±Ã—Ïƒå®Ÿé¨“çµæœï¼ˆæ‰‹å‹•é›†è¨ˆï¼‰\n",
    "alpha_sigma_results = {\n",
    "    'Condition': ['baseline', 'high_alpha', 'high_sigma', 'high_both'],\n",
    "    'Î±': [2.0, 5.0, 2.0, 5.0],\n",
    "    'Ïƒ': [2.0, 2.0, 5.0, 5.0],\n",
    "    'L2_norm': [5.237, 4.295, 10.901, 38.053],\n",
    "    'Steering_win_rate': [0.40, 0.30, 0.70, 0.00],\n",
    "    'Base_wins': [6, 7, 3, 10],\n",
    "    'Steering_wins': [4, 3, 7, 0],\n",
    "}\n",
    "\n",
    "df_alpha_sigma = pd.DataFrame(alpha_sigma_results)\n",
    "df_alpha_sigma['L2_change'] = ((df_alpha_sigma['L2_norm'] / df_alpha_sigma.loc[0, 'L2_norm']) - 1) * 100\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"Î±Ã—Ïƒèª¿æ•´å®Ÿé¨“çµæœï¼ˆãƒšãƒ«ã‚½ãƒŠ: episode-184019_Aï¼‰\")\n",
    "print(\"=\"*80)\n",
    "print(df_alpha_sigma.to_string(index=False))\n",
    "print(\"\\n\")\n",
    "\n",
    "# ç›®æ¨™é”æˆåˆ¤å®š\n",
    "print(\"ğŸ¯ ç›®æ¨™é”æˆçŠ¶æ³:\")\n",
    "print(\"  ç›®æ¨™1: L2 norm > 5.0\")\n",
    "print(\"  ç›®æ¨™2: Steeringå‹ç‡ > 50%\\n\")\n",
    "\n",
    "for _, row in df_alpha_sigma.iterrows():\n",
    "    l2_ok = \"âœ…\" if row['L2_norm'] > 5.0 else \"âŒ\"\n",
    "    win_ok = \"âœ…\" if row['Steering_win_rate'] > 0.5 else \"âŒ\"\n",
    "    both_ok = \"âœ…âœ…\" if (row['L2_norm'] > 5.0 and row['Steering_win_rate'] > 0.5) else \"âŒ\"\n",
    "    print(f\"  {row['Condition']:<12} L2={row['L2_norm']:>6.2f} {l2_ok}  å‹ç‡={row['Steering_win_rate']:.0%} {win_ok}  â†’ {both_ok}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯è¦–åŒ–\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# L2 Normæ¯”è¼ƒ\n",
    "ax1 = axes[0]\n",
    "colors = ['blue', 'orange', 'green', 'red']\n",
    "bars = ax1.bar(df_alpha_sigma['Condition'], df_alpha_sigma['L2_norm'], color=colors, alpha=0.7)\n",
    "ax1.axhline(y=5.0, color='red', linestyle='--', label='Target (L2 > 5.0)')\n",
    "ax1.set_ylabel('L2 Norm', fontsize=12)\n",
    "ax1.set_title('L2 Norm by Condition', fontsize=14, fontweight='bold')\n",
    "ax1.legend()\n",
    "ax1.grid(axis='y', alpha=0.3)\n",
    "\n",
    "for bar, val in zip(bars, df_alpha_sigma['L2_norm']):\n",
    "    ax1.text(bar.get_x() + bar.get_width()/2, val + 1, f'{val:.2f}', \n",
    "             ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# Steeringå‹ç‡æ¯”è¼ƒ\n",
    "ax2 = axes[1]\n",
    "bars = ax2.bar(df_alpha_sigma['Condition'], df_alpha_sigma['Steering_win_rate']*100, color=colors, alpha=0.7)\n",
    "ax2.axhline(y=50, color='red', linestyle='--', label='Target (>50%)')\n",
    "ax2.set_ylabel('Steering Win Rate (%)', fontsize=12)\n",
    "ax2.set_title('Steering Win Rate by Condition', fontsize=14, fontweight='bold')\n",
    "ax2.set_ylim([0, 100])\n",
    "ax2.legend()\n",
    "ax2.grid(axis='y', alpha=0.3)\n",
    "\n",
    "for bar, val in zip(bars, df_alpha_sigma['Steering_win_rate']*100):\n",
    "    ax2.text(bar.get_x() + bar.get_width()/2, val + 2, f'{val:.0f}%', \n",
    "             ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('alpha_sigma_comparison.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nâœ… ã‚°ãƒ©ãƒ•ä¿å­˜: alpha_sigma_comparison.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ”¬ é‡è¦ãªç™ºè¦‹\n",
    "\n",
    "#### âŒ ç™ºè¦‹1: Î±ã®å¢—åŠ ã¯é€†åŠ¹æœ\n",
    "\n",
    "- **high_alpha** (Î±=5.0, Ïƒ=2.0): L2=4.295 (**-18%**)\n",
    "- å‹ç‡ã‚‚ä½ä¸‹: 40% â†’ 30%\n",
    "\n",
    "**ç†ç”±**:\n",
    "- Î±ãŒå¤§ãã„ â†’ å°ã•ãªé‡ã¿ã§ã‚‚å¼·ã„åŠ¹æœãŒå‡ºã‚‹\n",
    "- CMA-ESãŒã€Œå°ã•ãªé‡ã¿ã§ååˆ†ã€ã¨å­¦ç¿’ã—ã¦ã—ã¾ã†\n",
    "- çµæœ: ã‚ˆã‚Šå°ã•ãªé‡ã¿ã«åæŸ â†’ L2ãƒãƒ«ãƒ æ¸›å°‘\n",
    "\n",
    "#### âœ… ç™ºè¦‹2: Ïƒã®å¢—åŠ ãŒæœ¬è³ªçš„ãªè§£æ±ºç­–\n",
    "\n",
    "- **high_sigma** (Î±=2.0, Ïƒ=5.0): L2=10.901 (**+108%**) âœ…âœ…\n",
    "- å‹ç‡ã‚‚å¤§å¹…æ”¹å–„: 40% â†’ **70%** âœ…âœ…\n",
    "\n",
    "**ç†ç”±**:\n",
    "- ÏƒãŒå¤§ãã„ â†’ ã‚ˆã‚Šåºƒã„æ¢ç´¢ç©ºé–“ã‚’æ¢ç´¢\n",
    "- å¤§ããªé‡ã¿ã‚’ç™ºè¦‹ã§ãã‚‹\n",
    "- ä¾‹: R2ã®é‡ã¿ baseline=-0.79 â†’ high_sigma=**-9.31** (11.8å€!)\n",
    "\n",
    "#### âš ï¸ ç™ºè¦‹3: ä¸¡æ–¹ã‚’ä¸Šã’ã‚‹ã¨éå‰°\n",
    "\n",
    "- **high_both** (Î±=5.0, Ïƒ=5.0): L2=38.053 (éå‰°ã«å¤§ãã„)\n",
    "- å‹ç‡: **0%** (ç”ŸæˆãŒå´©ã‚ŒãŸå¯èƒ½æ€§)\n",
    "\n",
    "**çµè«–**: **Ïƒ=5.0, Î±=2.0ãŒæœ€é©**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Part 2: Ïƒ=5.0å…¨ãƒšãƒ«ã‚½ãƒŠæœ€é©åŒ–çµæœ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ïƒ=5.0æœ€é©åŒ–çµæœã®èª­ã¿è¾¼ã¿\n",
    "results_dir = Path(\"../optimization_results_sigma5\")\n",
    "\n",
    "results = []\n",
    "for persona_dir in sorted(results_dir.glob(\"episode-*\")):\n",
    "    summary_file = persona_dir / \"summary.json\"\n",
    "    if summary_file.exists():\n",
    "        with open(summary_file) as f:\n",
    "            data = json.load(f)\n",
    "            results.append({\n",
    "                \"persona_id\": data[\"persona_id\"],\n",
    "                \"best_score\": data[\"best_score\"],\n",
    "                \"l2_norm\": data[\"l2_norm\"],\n",
    "                \"iterations\": data[\"iterations\"],\n",
    "                \"duration_minutes\": data[\"duration_seconds\"] / 60\n",
    "            })\n",
    "\n",
    "df_sigma5 = pd.DataFrame(results)\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(f\"Ïƒ=5.0å…¨ãƒšãƒ«ã‚½ãƒŠæœ€é©åŒ–çµæœï¼ˆN={len(df_sigma5)}ï¼‰\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nğŸ“Š çµ±è¨ˆã‚µãƒãƒªãƒ¼:\")\n",
    "print(f\"  L2 Norm: Mean={df_sigma5['l2_norm'].mean():.2f}, Median={df_sigma5['l2_norm'].median():.2f}, Min={df_sigma5['l2_norm'].min():.2f}, Max={df_sigma5['l2_norm'].max():.2f}\")\n",
    "print(f\"  Best Score: Mean={df_sigma5['best_score'].mean():.2f}, Median={df_sigma5['best_score'].median():.2f}\")\n",
    "print(f\"  Duration: Mean={df_sigma5['duration_minutes'].mean():.1f}m, Total={df_sigma5['duration_minutes'].sum()/60:.1f}h\\n\")\n",
    "\n",
    "# æˆåŠŸç‡\n",
    "perfect_score = (df_sigma5['best_score'] == 5.0).sum()\n",
    "high_l2 = (df_sigma5['l2_norm'] > 5.0).sum()\n",
    "success = ((df_sigma5['best_score'] == 5.0) & (df_sigma5['l2_norm'] > 5.0)).sum()\n",
    "\n",
    "print(f\"âœ… æˆåŠŸç‡:\")\n",
    "print(f\"  Perfect Score (5.0): {perfect_score}/{len(df_sigma5)} ({perfect_score/len(df_sigma5)*100:.1f}%)\")\n",
    "print(f\"  L2 > 5.0: {high_l2}/{len(df_sigma5)} ({high_l2/len(df_sigma5)*100:.1f}%)\")\n",
    "print(f\"  ä¸¡æ–¹é”æˆ: {success}/{len(df_sigma5)} ({success/len(df_sigma5)*100:.1f}%)\\n\")\n",
    "\n",
    "# è©³ç´°ãƒ†ãƒ¼ãƒ–ãƒ«\n",
    "df_sigma5['success'] = (df_sigma5['best_score'] == 5.0) & (df_sigma5['l2_norm'] > 5.0)\n",
    "df_sigma5['status'] = df_sigma5['success'].map({True: 'âœ…', False: 'âš ï¸'})\n",
    "print(df_sigma5[['persona_id', 'best_score', 'l2_norm', 'iterations', 'duration_minutes', 'status']].to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# L2 Normåˆ†å¸ƒã®å¯è¦–åŒ–\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# 1. L2 Normåˆ†å¸ƒï¼ˆãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ï¼‰\n",
    "ax1 = axes[0, 0]\n",
    "ax1.hist(df_sigma5['l2_norm'], bins=15, color='steelblue', alpha=0.7, edgecolor='black')\n",
    "ax1.axvline(x=5.0, color='red', linestyle='--', linewidth=2, label='Target (L2 > 5.0)')\n",
    "ax1.axvline(x=df_sigma5['l2_norm'].mean(), color='green', linestyle='--', linewidth=2, label=f'Mean ({df_sigma5[\"l2_norm\"].mean():.2f})')\n",
    "ax1.set_xlabel('L2 Norm', fontsize=11)\n",
    "ax1.set_ylabel('Count', fontsize=11)\n",
    "ax1.set_title('L2 Norm Distribution (N=28)', fontsize=13, fontweight='bold')\n",
    "ax1.legend()\n",
    "ax1.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# 2. Best Scoreåˆ†å¸ƒ\n",
    "ax2 = axes[0, 1]\n",
    "score_counts = df_sigma5['best_score'].value_counts().sort_index()\n",
    "ax2.bar(score_counts.index.astype(str), score_counts.values, color='coral', alpha=0.7, edgecolor='black')\n",
    "ax2.set_xlabel('Best Score', fontsize=11)\n",
    "ax2.set_ylabel('Count', fontsize=11)\n",
    "ax2.set_title('Best Score Distribution', fontsize=13, fontweight='bold')\n",
    "ax2.grid(axis='y', alpha=0.3)\n",
    "\n",
    "for i, (score, count) in enumerate(score_counts.items()):\n",
    "    ax2.text(i, count + 0.3, str(count), ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# 3. L2 vs Best Scoreæ•£å¸ƒå›³\n",
    "ax3 = axes[1, 0]\n",
    "success_mask = df_sigma5['success']\n",
    "ax3.scatter(df_sigma5.loc[~success_mask, 'l2_norm'], df_sigma5.loc[~success_mask, 'best_score'], \n",
    "            color='gray', alpha=0.6, s=100, label='Failed', edgecolors='black')\n",
    "ax3.scatter(df_sigma5.loc[success_mask, 'l2_norm'], df_sigma5.loc[success_mask, 'best_score'], \n",
    "            color='green', alpha=0.7, s=100, label='Success', edgecolors='black')\n",
    "ax3.axvline(x=5.0, color='red', linestyle='--', alpha=0.5)\n",
    "ax3.axhline(y=5.0, color='red', linestyle='--', alpha=0.5)\n",
    "ax3.set_xlabel('L2 Norm', fontsize=11)\n",
    "ax3.set_ylabel('Best Score', fontsize=11)\n",
    "ax3.set_title('L2 Norm vs Best Score', fontsize=13, fontweight='bold')\n",
    "ax3.legend()\n",
    "ax3.grid(alpha=0.3)\n",
    "\n",
    "# 4. Duration vs Best Score\n",
    "ax4 = axes[1, 1]\n",
    "ax4.scatter(df_sigma5['duration_minutes'], df_sigma5['best_score'], \n",
    "            c=df_sigma5['l2_norm'], cmap='viridis', s=100, alpha=0.7, edgecolors='black')\n",
    "cbar = plt.colorbar(ax4.collections[0], ax=ax4)\n",
    "cbar.set_label('L2 Norm', fontsize=10)\n",
    "ax4.set_xlabel('Duration (minutes)', fontsize=11)\n",
    "ax4.set_ylabel('Best Score', fontsize=11)\n",
    "ax4.set_title('Duration vs Best Score (colored by L2 Norm)', fontsize=13, fontweight='bold')\n",
    "ax4.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('sigma5_results_overview.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nâœ… ã‚°ãƒ©ãƒ•ä¿å­˜: sigma5_results_overview.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# L2 Normç¯„å›²åˆ¥ã®åˆ†å¸ƒ\n",
    "ranges = [\n",
    "    (0, 5, '< 5.0 (Too weak)'),\n",
    "    (5, 10, '5-10 (Acceptable)'),\n",
    "    (10, 15, '10-15 (Good)'),\n",
    "    (15, 100, '> 15 (Strong)')\n",
    "]\n",
    "\n",
    "print(\"\\nğŸ“Š L2 Normåˆ†å¸ƒ:\")\n",
    "for low, high, label in ranges:\n",
    "    count = ((df_sigma5['l2_norm'] >= low) & (df_sigma5['l2_norm'] < high)).sum()\n",
    "    print(f\"  {label:<25} {count:>3} ({count/len(df_sigma5)*100:>5.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. å®Ÿéš›ã®ç”Ÿæˆä¾‹æ¯”è¼ƒ: Base vs Steering vs Ground Truth\n",
    "\n",
    "æˆåŠŸä¾‹ã¨å¤±æ•—ä¾‹ã‹ã‚‰ä»£è¡¨çš„ãªãƒšãƒ«ã‚½ãƒŠã‚’é¸ã‚“ã§ã€å®Ÿéš›ã®ç”Ÿæˆçµæœã‚’æ¯”è¼ƒã—ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æˆåŠŸä¾‹ã¨å¤±æ•—ä¾‹ã‚’é¸æŠ\n",
    "success_personas = df_sigma5[df_sigma5['success']].sort_values('l2_norm', ascending=False).head(3)\n",
    "failed_personas = df_sigma5[~df_sigma5['success']].sort_values('l2_norm').head(3)\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"é¸æŠã•ã‚ŒãŸã‚µãƒ³ãƒ—ãƒ«ãƒšãƒ«ã‚½ãƒŠ\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nâœ… æˆåŠŸä¾‹ (Top 3 by L2 Norm):\")\n",
    "print(success_personas[['persona_id', 'l2_norm', 'best_score']].to_string(index=False))\n",
    "print(\"\\nâš ï¸ å¤±æ•—ä¾‹ (Bottom 3 by L2 Norm):\")\n",
    "print(failed_personas[['persona_id', 'l2_norm', 'best_score']].to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç”Ÿæˆæ¯”è¼ƒé–¢æ•°\n",
    "from persona_opt.internal_steering_l3 import InternalSteeringL3\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "def compare_generations(persona_id, prompt_idx=0, device=\"cuda:0\"):\n",
    "    \"\"\"\n",
    "    Base, Steering, Ground Truthã®ç”Ÿæˆçµæœã‚’æ¯”è¼ƒ\n",
    "    \"\"\"\n",
    "    # Load test turns\n",
    "    test_turns_path = Path(f\"../personas_cc/{persona_id}/test_turns_selected.json\")\n",
    "    if not test_turns_path.exists():\n",
    "        test_turns_path = Path(f\"../personas_cc/{persona_id}/test_turns.json\")\n",
    "    \n",
    "    with open(test_turns_path) as f:\n",
    "        data = json.load(f)\n",
    "        turn = data[\"turns\"][prompt_idx]\n",
    "    \n",
    "    prompt = turn[\"user_message\"]\n",
    "    ground_truth = turn[\"assistant_message\"]\n",
    "    \n",
    "    # Load best weights\n",
    "    weights_file = Path(f\"../optimization_results_sigma5/{persona_id}/{persona_id}_best_weights.json\")\n",
    "    with open(weights_file) as f:\n",
    "        best_weights = json.load(f)\n",
    "    \n",
    "    # Initialize model and steering\n",
    "    print(f\"\\nğŸ”„ Loading model for {persona_id}...\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Meta-Llama-3-8B-Instruct\")\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        \"meta-llama/Meta-Llama-3-8B-Instruct\",\n",
    "        torch_dtype=torch.bfloat16,\n",
    "        device_map=device\n",
    "    )\n",
    "    \n",
    "    steering = InternalSteeringL3(\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        layer=20,\n",
    "        alpha=2.0\n",
    "    )\n",
    "    \n",
    "    # Base generation\n",
    "    print(\"  Generating: Base...\")\n",
    "    base_response = steering.generate(prompt, weights=None)\n",
    "    \n",
    "    # Steering generation\n",
    "    print(\"  Generating: Steering...\")\n",
    "    steering_response = steering.generate(prompt, weights=best_weights)\n",
    "    \n",
    "    # Clean up\n",
    "    del model, steering\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    return {\n",
    "        \"persona_id\": persona_id,\n",
    "        \"prompt\": prompt,\n",
    "        \"base\": base_response,\n",
    "        \"steering\": steering_response,\n",
    "        \"ground_truth\": ground_truth,\n",
    "        \"weights\": best_weights\n",
    "    }\n",
    "\n",
    "def print_comparison(result):\n",
    "    \"\"\"\n",
    "    æ¯”è¼ƒçµæœã‚’è¦‹ã‚„ã™ãè¡¨ç¤º\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(f\"Persona: {result['persona_id']}\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Weights info\n",
    "    weights = result['weights']\n",
    "    l2_norm = np.sqrt(sum(w**2 for w in weights.values()))\n",
    "    print(f\"\\nğŸ“Š Weights (L2={l2_norm:.2f}):\")\n",
    "    for trait, weight in weights.items():\n",
    "        print(f\"  {trait}: {weight:>7.3f}\")\n",
    "    \n",
    "    print(f\"\\nğŸ’¬ Prompt:\\n{result['prompt']}\")\n",
    "    print(f\"\\nğŸ¤– Base Response:\\n{result['base']}\")\n",
    "    print(f\"\\nğŸ¯ Steering Response:\\n{result['steering']}\")\n",
    "    print(f\"\\nâœ… Ground Truth:\\n{result['ground_truth']}\")\n",
    "    print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æˆåŠŸä¾‹ã®ç”Ÿæˆæ¯”è¼ƒï¼ˆ1ä¾‹ï¼‰\n",
    "success_persona = success_personas.iloc[0]['persona_id']\n",
    "print(f\"\\nğŸ” æˆåŠŸä¾‹ã®ç”Ÿæˆæ¯”è¼ƒ: {success_persona}\")\n",
    "result_success = compare_generations(success_persona, prompt_idx=0)\n",
    "print_comparison(result_success)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¤±æ•—ä¾‹ã®ç”Ÿæˆæ¯”è¼ƒï¼ˆ1ä¾‹ï¼‰\n",
    "failed_persona = failed_personas.iloc[0]['persona_id']\n",
    "print(f\"\\nğŸ” å¤±æ•—ä¾‹ã®ç”Ÿæˆæ¯”è¼ƒ: {failed_persona}\")\n",
    "result_failed = compare_generations(failed_persona, prompt_idx=0)\n",
    "print_comparison(result_failed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. ç·åˆè€ƒå¯Ÿ\n",
    "\n",
    "### ä¸»ãªç™ºè¦‹\n",
    "\n",
    "1. **Ïƒ=5.0ãŒåŠ¹æœçš„**: L2å¹³å‡10.05ï¼ˆÏƒ=2.0ã®ç´„2å€ï¼‰\n",
    "2. **Î±å¢—åŠ ã¯é€†åŠ¹æœ**: CMA-ESãŒå°ã•ãªé‡ã¿ã«åæŸã—ã¦ã—ã¾ã†\n",
    "3. **æˆåŠŸç‡39.3%**: ã¾ã æ”¹å–„ã®ä½™åœ°ã‚ã‚Š\n",
    "\n",
    "### å¤±æ•—ãƒ‘ã‚¿ãƒ¼ãƒ³ã®åˆ†æ\n",
    "\n",
    "- Best Score=2.5ã§æ—©æœŸçµ‚äº†ï¼ˆ16/28ãƒšãƒ«ã‚½ãƒŠï¼‰\n",
    "- å®Ÿè¡Œæ™‚é–“3-5åˆ†ï¼ˆæ­£å¸¸ã¯60-340åˆ†ï¼‰\n",
    "- åŸå› å€™è£œ:\n",
    "  1. CMA-ESãŒå±€æ‰€æœ€é©ã«é™¥ã£ã¦ã„ã‚‹\n",
    "  2. è©•ä¾¡é–¢æ•°ï¼ˆGPT-4ã«ã‚ˆã‚‹é¡ä¼¼åº¦åˆ¤å®šï¼‰ã®å•é¡Œ\n",
    "  3. ä¸€éƒ¨ã®ãƒšãƒ«ã‚½ãƒŠã¯trait vectorsã§è¡¨ç¾ã—ã«ãã„\n",
    "\n",
    "### æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—\n",
    "\n",
    "1. **æ—©æœŸçµ‚äº†ãƒšãƒ«ã‚½ãƒŠã®å†æœ€é©åŒ–**\n",
    "   - ç•°ãªã‚‹åˆæœŸå€¤ã€ã‚ˆã‚Šé•·ã„iterations\n",
    "2. **è©•ä¾¡é–¢æ•°ã®æ”¹å–„**\n",
    "   - Human evaluation\n",
    "   - ã‚ˆã‚Šè©³ç´°ãªé¡ä¼¼åº¦æŒ‡æ¨™\n",
    "3. **Adaptive trait selection**\n",
    "   - ãƒšãƒ«ã‚½ãƒŠã”ã¨ã«æœ€é©ãªtraitçµ„ã¿åˆã‚ã›ã‚’é¸æŠ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. çµè«–\n",
    "\n",
    "### âœ… é”æˆã—ãŸã“ã¨\n",
    "\n",
    "- Ïƒ=5.0ã«ã‚ˆã‚Š **L2å¹³å‡10.05ã‚’é”æˆ**ï¼ˆç›®æ¨™5.0ã®2å€ï¼‰\n",
    "- 1ãƒšãƒ«ã‚½ãƒŠå®Ÿé¨“ã§ **Steeringå‹ç‡70%ã‚’é”æˆ**ï¼ˆbaseline 40%ã‹ã‚‰æ”¹å–„ï¼‰\n",
    "- 26/28ãƒšãƒ«ã‚½ãƒŠ (92.9%)ã§L2 > 5.0ã‚’é”æˆ\n",
    "\n",
    "### âš ï¸ èª²é¡Œ\n",
    "\n",
    "- å…¨ä½“æˆåŠŸç‡39.3%ï¼ˆä¸¡æ¡ä»¶é”æˆï¼‰\n",
    "- 16ãƒšãƒ«ã‚½ãƒŠãŒæ—©æœŸçµ‚äº†ï¼ˆBest Score=2.5ï¼‰\n",
    "- å„ãƒšãƒ«ã‚½ãƒŠã®Steeringå‹ç‡ã¯æœªè©•ä¾¡\n",
    "\n",
    "### ğŸ¯ æ¨å¥¨è¨­å®š\n",
    "\n",
    "**æœ€é©ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿**: Î±=2.0, Ïƒ=5.0, max_iterations=50, population_size=8\n",
    "\n",
    "---\n",
    "\n",
    "**ãƒ¬ãƒãƒ¼ãƒˆä½œæˆæ—¥**: 2026-01-10  \n",
    "**å®Ÿè¡Œæ™‚é–“**: 35.3æ™‚é–“ï¼ˆ28ãƒšãƒ«ã‚½ãƒŠï¼‰"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
